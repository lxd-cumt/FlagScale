defaults:
  - _self_
  - train: train_emu3_7b

experiment:
  exp_name: Emu3_7b
  seed: 2024
  save_steps: 1000
  load: null
  exp_dir: /share/project/zhaoyingli/gitee/Experiments/${experiment.exp_name}
  task:
    type: train
    backend: megatron
    entrypoint: flagscale/train/train_emu3.py
  runner:
    type: cloud
    rdzv_id: jiuding-emu3
    rdzv_conf: join_timeout=3600,read_timeout=3600,timeout=540
    nnodes: ${oc.env:WORLD_SIZE}
    node_rank: ${oc.env:RANK}
    nproc_per_node: 8
    master_addr: ${oc.env:MASTER_ADDR}
    master_port: 12345
    max_restarts: 6553600
    no_shared_fs: false
  envs:
    LOGLEVEL: "INFO"
    NVTE_FUSED_ATTN: 0
    CUDA_VISIBLE_DEVICES: "0,1,2,3,4,5,6,7"
    CUDA_DEVICE_MAX_CONNECTIONS: 1
    NCCL_SOCKET_IFNAME: eth0
    NCCL_IB_DISABLE: 0
    NCCL_IB_CUDA_SUPPORT: 1
    NCCL_IB_GID_INDEX: 0
    NCCL_IB_TIMEOUT: 22
    NCCL_IB_RETRY_CNT: 13
    OMP_NUM_THREADS: 4
    GLOO_SOCKET_IFNAME: eth0
    NCCL_IB_HCA: mlx5_2,mlx5_5
  cmds:
    before_start: "ulimit -n 1048576"

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
